{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1ThX4UYntYVQ0iX5WlRgszLdLpOHhvjf-","authorship_tag":"ABX9TyN+JYGkYzt9Cnnt96E87cFj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["✅21. ¿Cuál es la aplicación con el nombre más largo? (⭐)\n"],"metadata":{"id":"6MAx_vRiElwY"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YFlnfdn4ENAg","executionInfo":{"status":"ok","timestamp":1696636398863,"user_tz":180,"elapsed":35200,"user":{"displayName":"juani perez di chiazza","userId":"03942028392799934907"}},"outputId":"89c1deb1-3a04-4914-96c4-ee4c820db3be"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=082c011838aaea30b8c4da414aebd75f3d2679215270510c646d8c6524e7e0ff\n","  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.5.0\n","Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n","Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n","Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n","Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,342 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,266 kB]\n","Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Fetched 2,950 kB in 1s (2,094 kB/s)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","18 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"]}],"source":["!pip install pyspark\n","!apt update"]},{"cell_type":"code","source":["from pyspark.sql import *\n","from pyspark.sql.functions import *\n","from pyspark import SparkContext\n","from pyspark.sql import SQLContext"],"metadata":{"id":"I558xJGEE5Py","executionInfo":{"status":"ok","timestamp":1696636398864,"user_tz":180,"elapsed":16,"user":{"displayName":"juani perez di chiazza","userId":"03942028392799934907"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"id":"95hmuJFSUAaC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696636525829,"user_tz":180,"elapsed":126978,"user":{"displayName":"juani perez di chiazza","userId":"03942028392799934907"}},"outputId":"c3f852a4-0846-44f2-ab57-bc384aeb9864"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["spark = SparkSession.builder.getOrCreate()\n","sc = spark.sparkContext"],"metadata":{"id":"Gq9bEgmJEkav","executionInfo":{"status":"ok","timestamp":1696636531098,"user_tz":180,"elapsed":5284,"user":{"displayName":"juani perez di chiazza","userId":"03942028392799934907"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["sqlContext = SQLContext(sc)\n","# Atencion, utilizo estos metodos para separar bien la forma en la que se lee del csv, ya que sino se lee de manera incorrecta en algunos casoa\n","app_data = sqlContext.read.option(\"delimiter\", \",\").option(\"escape\", '\"').csv('/content/drive/MyDrive/aa-OrgaDeDatos/googleplaystore.csv', header=True, inferSchema=True)\n","app_reviews = sqlContext.read.option(\"delimiter\", \",\").option(\"escape\", '\"').csv('/content/drive/MyDrive/aa-OrgaDeDatos/googleplaystore_user_reviews.csv', header=True, inferSchema=True)\n","rdd_app_data = app_data.rdd\n","rdd_app_reviews = app_reviews.rdd"],"metadata":{"id":"YovIdPJQEkw3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696636543965,"user_tz":180,"elapsed":12875,"user":{"displayName":"juani perez di chiazza","userId":"03942028392799934907"}},"outputId":"ac1eacdf-8d83-4a1d-dad0-f1987c5f65da"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pyspark/sql/context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["largest2 = rdd_app_data.map(lambda row: row[\"App\"]).reduce(lambda a, b: a if len(a) >= len(b) else b)\n","largest1 = rdd_app_reviews.map(lambda row: row[\"App\"]).reduce(lambda a, b: a if len(a) >= len(b) else b)\n","print(largest1, \"\\n\", largest2)\n","# Lo mismo que antes! =)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6hPISviAbpsK","executionInfo":{"status":"ok","timestamp":1696636774661,"user_tz":180,"elapsed":1717,"user":{"displayName":"juani perez di chiazza","userId":"03942028392799934907"}},"outputId":"80185632-723d-462e-962a-de1599c4ff05"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["591房屋交易-租屋、中古屋、新建案、實價登錄、別墅透天、公寓套房、捷運、買房賣房行情、房價房貸查詢 \n"," 591 housing transactions - renting houses, middle-class houses, new cases, real-time registration, villas through the sky, apartment suites, MRT, buying a house selling prices, housing mortgages\n"]}]},{"cell_type":"code","source":["# Se puede hacer con .max de manera sencilla pero por lo pedido lo hago con map reduce :)\n","# largest1 = rdd_app_reviews.max(key= lambda row: len(row[\"App\"]))[\"App\"]\n","# largest2 = rdd_app_data.max(key=lambda row: len(row[1][\"App\"]))[\"App\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K-CRIGIhGLeJ","executionInfo":{"status":"ok","timestamp":1696636728238,"user_tz":180,"elapsed":3339,"user":{"displayName":"juani perez di chiazza","userId":"03942028392799934907"}},"outputId":"8dd476fb-6c5d-4065-bd0f-61bce68dc8e0"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["591房屋交易-租屋、中古屋、新建案、實價登錄、別墅透天、公寓套房、捷運、買房賣房行情、房價房貸查詢 \n"," 591 housing transactions - renting houses, middle-class houses, new cases, real-time registration, villas through the sky, apartment suites, MRT, buying a house selling prices, housing mortgages\n"]}]}]}