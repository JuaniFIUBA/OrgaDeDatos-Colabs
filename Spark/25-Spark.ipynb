{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1GmH1A04EP_gKjesBofuFv6crYwhTV1Se","authorship_tag":"ABX9TyNeviQo0PKYF/D4wzmvlHWX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["✅25. Indicar el nombre y el tamaño de las aplicaciones educativas. (⭐)\n"],"metadata":{"id":"-Zqga344Ihda"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YFlnfdn4ENAg","executionInfo":{"status":"ok","timestamp":1696881386682,"user_tz":180,"elapsed":57875,"user":{"displayName":"juani perez di chiazza","userId":"03942028392799934907"}},"outputId":"aea4905f-ecaa-42a1-8371-c6bc41d6abb3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=744d4a6bbc81cdfd4f852131fa754dd55213ffff35778cec2dca94f1b78f6cbd\n","  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.5.0\n","Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n","Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n","Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n","Get:8 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,081 kB]\n","Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,343 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,267 kB]\n","Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,002 kB]\n","Hit:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Fetched 5,034 kB in 4s (1,234 kB/s)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","22 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"]}],"source":["!pip install pyspark\n","!apt update"]},{"cell_type":"code","source":["from pyspark.sql import *\n","from pyspark.sql.functions import *\n","from pyspark import SparkContext\n","from pyspark.sql import SQLContext"],"metadata":{"id":"I558xJGEE5Py"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ZtgGLaUQXtI","executionInfo":{"status":"ok","timestamp":1696881397092,"user_tz":180,"elapsed":10415,"user":{"displayName":"juani perez di chiazza","userId":"03942028392799934907"}},"outputId":"40ed763b-06d1-4d78-afa5-fca6fbe14c3f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["spark = SparkSession.builder.getOrCreate()\n","sc = spark.sparkContext"],"metadata":{"id":"Gq9bEgmJEkav"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sqlContext = SQLContext(sc)\n","# Atencion, utilizo estos metodos para separar bien la forma en la que se lee del csv, ya que sino se lee de manera incorrecta en algunos casoa\n","app_data = sqlContext.read.option(\"delimiter\", \",\").option(\"escape\", '\"').csv('/content/drive/MyDrive/aa-OrgaDeDatos/googleplaystore.csv', header=True, inferSchema=True)\n","rdd_app_data = app_data.rdd"],"metadata":{"id":"YovIdPJQEkw3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696881427268,"user_tz":180,"elapsed":19738,"user":{"displayName":"juani perez di chiazza","userId":"03942028392799934907"}},"outputId":"6793cf24-e85b-49b1-b93a-c0524f984159"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pyspark/sql/context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# Hago esto para poder \"droppear\" las repetidas. Use este metodo porque distinct elimina la fila si y solo si todos los campos de dos filas coinciden, cosa que\n","# no pasa en este caso. Hay apps que tienen todos los campos iguales y difieren por algunas reviews, lo que puede afectar al resultado final en este caso.\n","def get_key(x):\n","    return \"{0}\".format(x[\"App\"])\n","rdd_app_data_filtered = rdd_app_data.map(lambda x: (get_key(x), x)).reduceByKey(lambda x,y: x)"],"metadata":{"id":"6gb1jtssJ1lz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["La app que elimino es una app que tiene un problema al utilizar el take, al ser arabe se muestra mal, mixea el nombre y el size, por lo que decido eliminarla"],"metadata":{"id":"3aNpeXXn4SZ5"}},{"cell_type":"code","source":["education_rows = rdd_app_data_filtered.filter(lambda row: row[1][\"Category\"] == \"EDUCATION\" and row[1][\"App\"] != \"Flame - درب عقلك يوميا\").map(lambda row: (row[1][\"App\"], row[1][\"Size\"]))\n","education_rows.take(20)\n","\n","# Utilizo el [1] para indexar previo al valor de la row por como quedo definido para droppear las filas repetidas previamente el rdd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qt6brZIVK_nj","executionInfo":{"status":"ok","timestamp":1696883664909,"user_tz":180,"elapsed":1318,"user":{"displayName":"juani perez di chiazza","userId":"03942028392799934907"}},"outputId":"598945dd-d82b-4f44-ef62-9947e5188140"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Duolingo: Learn Languages Free', 'Varies with device'),\n"," ('TED', '18M'),\n"," ('English Communication - Learn English for Chinese (Learn English for Chinese)',\n","  '18M'),\n"," ('Khan Academy', '21M'),\n"," ('Learn English with Wlingua', '3.3M'),\n"," ('Ai La Trieu Phu - ALTP Free', '24M'),\n"," ('Princess Coloring Book', '39M'),\n"," ('Learn Spanish - Español', '3.2M'),\n"," ('English Grammar Test', '5.1M'),\n"," ('Speed Reading', '11M'),\n"," ('English for beginners', '27M'),\n"," ('Mermaids', 'Varies with device'),\n"," ('Learn Japanese, Korean, Chinese Offline & Free', '26M'),\n"," ('Kids Mode', '11M'),\n"," ('PBS KIDS Video', 'Varies with device'),\n"," ('Dinosaurs Coloring Pages', '41M'),\n"," ('Cars Coloring Pages', '49M'),\n"," ('Babbel – Learn Languages', '21M'),\n"," ('Math Tricks', '8.1M'),\n"," ('Monster Truck Driver & Racing', '51M')]"]},"metadata":{},"execution_count":10}]}]}